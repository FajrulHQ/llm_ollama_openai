{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62812\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (32.006348, 694.587265442, 516.881836143, 835.7212220228572)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n",
      "C:\\Users\\62812\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (32.006348, 718.993515442, 555.9448239889999, 858.24996086)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n"
     ]
    }
   ],
   "source": [
    "# Import modul yang diperlukan\n",
    "from IPython.display import Markdown\n",
    "from utils.document_processor import DocumentProcessor\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "# Inisialisasi DocumentProcessor dan OllamaLLM\n",
    "docs = DocumentProcessor()\n",
    "DATA_PATH = \"./data\"\n",
    "INDEX_PATH = \"faiss_index\"\n",
    "OLLAMA_MODEL = \"llama3.2\"\n",
    "COLLECTION_NAME = \"ollama_vectore_test\"\n",
    "EMBEDDING_MODEL = OllamaLLM(model=OLLAMA_MODEL)\n",
    "\n",
    "# Inisialisasi embedding model menggunakan HuggingFace\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Menghasilkan embedding dari teks menggunakan HuggingFace.\n",
    "    \"\"\"\n",
    "    return embedding_model.encode(text).tolist()\n",
    "\n",
    "# Langkah 1: Proses dokumen\n",
    "extracted_docs = []\n",
    "for filename in os.listdir(DATA_PATH):\n",
    "    valid_extensions = ('.pdf', '.docx', '.txt')\n",
    "    if not filename.lower().endswith(valid_extensions):\n",
    "        continue\n",
    "    \n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        document = f.read()\n",
    "        result = docs.process_document(document, filename)\n",
    "        extracted_docs.append(result)\n",
    "\n",
    "# Ambil konten plain_text untuk vektorisasi\n",
    "documents = [{\"text\": doc[3], \"metadata\": {\"filename\": filename}} for doc, filename in zip(extracted_docs, os.listdir(DATA_PATH))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langkah 2: Buat dokumen menjadi vektor\n",
    "texts = [doc[\"text\"] for doc in documents]\n",
    "metadatas = [doc[\"metadata\"] for doc in documents]\n",
    "\n",
    "# Buat FAISS Vectorstore dengan memberikan embedding instance\n",
    "vectorstore = FAISS.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=embedding_model,\n",
    "    metadatas=metadatas\n",
    ")\n",
    "\n",
    "# Simpan index lokal\n",
    "vectorstore.save_local(INDEX_PATH)\n",
    "\n",
    "# Langkah 3: Query dengan RAG\n",
    "query = \"Apa isi dokumen tentang topik X?\"\n",
    "query_embedding = embedding_model.embed_query(query)\n",
    "retrieved_docs = vectorstore.similarity_search_by_vector(query_embedding, k=3)\n",
    "\n",
    "# Gabungkan dokumen hasil pencarian untuk input ke model\n",
    "retrieved_text = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a summary of the text:\n",
       "\n",
       "The individual has worked as a technician in the telecommunications industry, providing internet services with the name \"Ofon O3\" in the Kepulauan Riau region. They have gained experience in configuring and optimizing network equipment, including optical fiber modems. Their work involves high initiative, particularly when installing internet services for customers, with an average customer satisfaction rate of 70-95%.\n",
       "\n",
       "The individual has also completed their studies at Universitas Riau, expected to graduate in August 2026, majoring in Informatics Engineering. During their studies, they have participated in various campus activities, including organizations and events, as well as independent research projects.\n",
       "\n",
       "In addition to their work experience and academic background, the individual has gained skills in areas such as:\n",
       "\n",
       "* Cloud computing\n",
       "* Cybersecurity\n",
       "* Programming languages (JavaScript, HTML5)\n",
       "* Database management (SQL)\n",
       "* Graphic design (Figma)\n",
       "* Network equipment configuration (Mikrotik)\n",
       "\n",
       "Soft skills include:\n",
       "\n",
       "* Public speaking\n",
       "* Fluent English language skills\n",
       "* Teamwork and collaboration\n",
       "* Adaptability\n",
       "* Time management\n",
       "\n",
       "Some of the individual's notable achievements include:\n",
       "\n",
       "* Winning a short story competition for Malay prose among SMA schools in the province of Kepulauan Riau.\n",
       "* Completing an independent research project on diabetes prevention solutions (Glusity).\n",
       "* Designing a new website landing page for Universitas Riau.\n",
       "\n",
       "Overall, the individual has gained a strong foundation in technical skills and soft skills, with experience in working in the telecommunications industry and participating in various academic and extracurricular activities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Template prompt\n",
    "template = \"\"\"\n",
    "  You are a helpful assistant for text summarization. \n",
    "  Only include information that is part of the document. \n",
    "  Do not include your own opinion or analysis.\n",
    "\n",
    "  Document: \n",
    "  \"{document}\"\n",
    "  Summary:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = OllamaLLM(model=OLLAMA_MODEL)\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke({\"document\": retrieved_text})\n",
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST OPENAI MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-35-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;43m        You are a helpful assistant for text summarization.\u001b[39;49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;43m        Only include information that is part of the document. \u001b[39;49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;43m        Do not include your own opinion or analysis.\u001b[39;49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;43m      \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrieved_text\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m  \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m Markdown(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:149\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[0;32m    141\u001b[0m         timeout,\n\u001b[0;32m    142\u001b[0m         stream,\n\u001b[0;32m    143\u001b[0m         headers,\n\u001b[0;32m    144\u001b[0m         request_timeout,\n\u001b[0;32m    145\u001b[0m         typed_api_type,\n\u001b[0;32m    146\u001b[0m         requestor,\n\u001b[0;32m    147\u001b[0m         url,\n\u001b[0;32m    148\u001b[0m         params,\n\u001b[1;32m--> 149\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__prepare_create_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:80\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[1;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     78\u001b[0m headers \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     79\u001b[0m request_timeout \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 80\u001b[0m typed_api_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_api_type_and_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_type\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_api_type \u001b[38;5;129;01min\u001b[39;00m (util\u001b[38;5;241m.\u001b[39mApiType\u001b[38;5;241m.\u001b[39mAZURE, util\u001b[38;5;241m.\u001b[39mApiType\u001b[38;5;241m.\u001b[39mAZURE_AD):\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deployment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\api_resources\\abstract\\api_resource.py:169\u001b[0m, in \u001b[0;36mAPIResource._get_api_type_and_version\u001b[1;34m(cls, api_type, api_version)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_api_type_and_version\u001b[39m(\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mcls\u001b[39m, api_type: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, api_version: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    165\u001b[0m ):\n\u001b[0;32m    166\u001b[0m     typed_api_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    167\u001b[0m         ApiType\u001b[38;5;241m.\u001b[39mfrom_str(api_type)\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m api_type\n\u001b[1;32m--> 169\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mApiType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[0;32m    171\u001b[0m     typed_api_version \u001b[38;5;241m=\u001b[39m api_version \u001b[38;5;129;01mor\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mapi_version\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (typed_api_type, typed_api_version)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\util.py:35\u001b[0m, in \u001b[0;36mApiType.from_str\u001b[1;34m(label)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_str\u001b[39m(label):\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazure\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ApiType\u001b[38;5;241m.\u001b[39mAZURE\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m label\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazure_ad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazuread\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model = \"gpt-35-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "  engine=model,\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\", \n",
    "      \"content\": \"\"\"\n",
    "        You are a helpful assistant for text summarization.\n",
    "        Only include information that is part of the document. \n",
    "        Do not include your own opinion or analysis.\n",
    "      \"\"\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": retrieved_text\n",
    "    }\n",
    "  ],\n",
    ")\n",
    "\n",
    "Markdown(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
