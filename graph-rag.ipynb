{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from utils.document_processor import DocumentProcessor\n",
    "from chromadb import Client\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "CHROMA_PATH = \"chroma\"\n",
    "DATA_PATH = \"./data\"\n",
    "VALID_EXTENSIONS = ('.pdf', '.docx', '.txt')\n",
    "\n",
    "docs = DocumentProcessor()\n",
    "chroma_client = Client()\n",
    "collection = chroma_client.get_or_create_collection(name=\"document_vectors\")\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def load_documents():\n",
    "    for filename in filter(lambda f: f.lower().endswith(VALID_EXTENSIONS), os.listdir(DATA_PATH)):\n",
    "        filepath = os.path.join(DATA_PATH, filename)\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            yield docs.process_document(f.read(), filename)\n",
    "\n",
    "def split_documents(extracted_docs, chunk_size=500):\n",
    "    for doc_index, (content, _, _, _) in enumerate(extracted_docs):\n",
    "        for page_number, page_content in enumerate(content or []):\n",
    "            for i in range(0, len(page_content), chunk_size):\n",
    "                chunk = page_content[i:i+chunk_size].strip()\n",
    "                if chunk:\n",
    "                    yield f\"doc{doc_index}_page{page_number}_chunk{i//chunk_size}\", chunk, doc_index, page_number\n",
    "\n",
    "def add_to_chroma(chunks):\n",
    "    existing_ids = set(collection.get(include=[]).get(\"ids\", []))\n",
    "    new_chunks = [(cid, embedding_model.encode([chunk])[0].tolist(), doc_idx, page)\n",
    "                  for cid, chunk, doc_idx, page in chunks if cid not in existing_ids]\n",
    "\n",
    "    if new_chunks:\n",
    "        ids, embeddings, metadata = zip(*[(cid, emb, {\"doc_index\": doc_idx, \"page\": page})\n",
    "                                           for cid, emb, doc_idx, page in new_chunks])\n",
    "        collection.add(ids=list(ids), embeddings=list(embeddings), metadatas=list(metadata))\n",
    "\n",
    "def main(reset=False):\n",
    "    if reset and os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "    add_to_chroma(split_documents(load_documents()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLLAMA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_MODEL = \"llama3.2\"\n",
    "COLLECTION_NAME = \"ollama_vectore_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST OLLAMA MODEL WITH GRAPHRAG v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def create_document_graph(documents):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for i, doc in enumerate(documents):\n",
    "        G.add_node(i, content=doc)\n",
    "        if i < len(documents) - 1:\n",
    "            G.add_edge(i, i + 1)\n",
    "    \n",
    "    return G\n",
    "\n",
    "def retrieve_relevant_documents(graph, query):\n",
    "    return [graph.nodes[n]['content'] for n in graph.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Agus Syuhada\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (21.19, 42.025999999999996, 416.0100000000002, 809.3267407407408)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n",
      "c:\\Users\\Agus Syuhada\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (21.19, 628.7959999999999, 235.94999999999993, 811.9193333333334)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This appears to be a collection of data about Indonesia, including geographical information, economic statistics, and cultural symbols. The data is presented in a structured format, with each piece of information enclosed in a set of curly brackets ({}).\n",
       "\n",
       "Here is a summary of the main points:\n",
       "\n",
       "* Geographical Information:\n",
       "\t+ Location: Asia Tenggara\n",
       "\t+ Borders: Malaysia, Filipina, Australia\n",
       "\t+ Highest Mountain: Puncak Jaya (4.884 mdpl)\n",
       "\t+ Longest River: Sungai Kapuas (±1.143 km)\n",
       "* Economic Statistics:\n",
       "\t+ GDP: ±1,3 triliun USD (perkiraan 2024)\n",
       "\t+ Sector of Economy: Pertanian, Pertambangan, Industri, Pariwisata\n",
       "\t+ Population: Not explicitly stated\n",
       "* Cultural Symbols:\n",
       "\t+ National Symbol: Garuda Pancasila\n",
       "\t+ National Anthem: Indonesia Raya\n",
       "\t+ National Flag: Merah Putih\n",
       "\t+ National Motto: Bhinneka Tunggal Ika\n",
       "\t+ National Mascot: Not explicitly stated\n",
       "\n",
       "Overall, this data provides a comprehensive overview of Indonesia's geography, economy, and cultural identity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import networkx as nx\n",
    "\n",
    "# Template untuk prompt summarization\n",
    "template = \"\"\"\n",
    "You are a helpful assistant for text summarization. \n",
    "Only include information that is part of the document. \n",
    "Do not include your own opinion or analysis.\n",
    "\n",
    "Document: \n",
    "\"{document}\"\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model=OLLAMA_MODEL)\n",
    "chain = prompt | model\n",
    "\n",
    "def create_document_graph(documents):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for i, doc in enumerate(documents):\n",
    "        G.add_node(i, content=doc)\n",
    "        \n",
    "        if i < len(documents) - 1:\n",
    "            G.add_edge(i, i + 1)\n",
    "    \n",
    "    return G\n",
    "\n",
    "def retrieve_relevant_documents(graph, query):\n",
    "    return [graph.nodes[n]['content'] for n in graph.nodes]\n",
    "\n",
    "def summarize_documents(documents, query):\n",
    "    graph = create_document_graph(documents)\n",
    "    \n",
    "    relevant_documents = retrieve_relevant_documents(graph, query)\n",
    "    \n",
    "    summaries = []\n",
    "    for doc_index, doc_data in enumerate(relevant_documents):\n",
    "        if not doc_data or len(doc_data) < 4:\n",
    "            continue\n",
    "        \n",
    "        content, _, _, _ = doc_data\n",
    "        full_text = \"\\n\".join(\n",
    "            \" \".join(map(str, page)) if isinstance(page, list) else str(page)\n",
    "            for page in content\n",
    "        ) if isinstance(content, list) else str(content)\n",
    "        \n",
    "        if not full_text.strip():\n",
    "            continue\n",
    "        \n",
    "        summaries.append(chain.invoke({\"document\": full_text}))\n",
    "    \n",
    "    return summaries\n",
    "\n",
    "documents = list(load_documents())\n",
    "query = \"What is discussed in this document?\" \n",
    "\n",
    "summaries = summarize_documents(documents, query)\n",
    "\n",
    "for summary in summaries:\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST OLLAMA MODEL WITH GRAPHRAG v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Agus Syuhada\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (21.19, 42.025999999999996, 416.0100000000002, 809.3267407407408)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n",
      "c:\\Users\\Agus Syuhada\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (21.19, 628.7959999999999, 235.94999999999993, 811.9193333333334)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The provided data appears to be a collection of information about Indonesia, including its geography, economy, politics, and culture. Here are some key points that can be extracted from the data:\n",
       "\n",
       "**Geography**\n",
       "\n",
       "* Location: Asia Tenggara (Southeastern Asia)\n",
       "* Borders: Malaysia and Filipina in the north, Australia in the south\n",
       "* Highest point: Puncak Jaya (4,884 m dpl)\n",
       "\n",
       "**Economy**\n",
       "\n",
       "* GDP: ±1.3 trillion USD (perkiraan 2024)\n",
       "* Main sectors: Pertanian (Agriculture), Pertambangan (Mining), Industri (Industry), and Pariwisata (Tourism)\n",
       "* Currency: Not specified\n",
       "\n",
       "**Politics**\n",
       "\n",
       "* Government type: Not specified\n",
       "* National symbol: Garuda Pancasila (National Emblem)\n",
       "* National anthem: Indonesia Raya (Lagu Kebangsaan)\n",
       "* National flag: Merah Putih (Red-White)\n",
       "\n",
       "**Culture**\n",
       "\n",
       "* Symbol of national unity: Bhinneka Tunggal Ika\n",
       "* National motto: Not specified\n",
       "\n",
       "**Data Umum Negara Indonesia**\n",
       "\n",
       "* A collection of general information about the Indonesian government and its institutions.\n",
       "\n",
       "Overall, the data provides a comprehensive overview of Indonesia's geography, economy, politics, culture, and other relevant aspects."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Insights ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here are some important insights that can be extracted from the summary:\n",
       "\n",
       "1. **Location and Borders**: Indonesia is situated in Southeastern Asia, sharing borders with Malaysia and the Philippines to the north, and Australia to the south.\n",
       "\n",
       "2. **Geography's Highest Point**: The country has a significant geographical feature, Puncak Jaya, which stands at 4,884 meters (dpl) above sea level.\n",
       "\n",
       "3. **Economic Sectors**: The primary sectors that drive Indonesia's economy are agriculture, mining, industry, and tourism.\n",
       "\n",
       "4. **Political Structure**: Although the government type is not specified in the provided data, it implies a complex structure since other national symbols such as the Garuda Pancasila emblem and the Indonesian national anthem, \"Indonesia Raya,\" are mentioned.\n",
       "\n",
       "5. **Cultural Significance**: The symbol of national unity for Indonesia is Bhinneka Tunggal Ika, which represents diversity within a united nation.\n",
       "\n",
       "6. **National Identity**: The country's national motto or any other defining phrases were not provided in the summary, indicating that their significance might be more nuanced and less explicitly expressed in the data given.\n",
       "\n",
       "7. **Economic Value**: Indonesia's GDP is significant, with an estimated value of ±1.3 trillion USD in 2024, making it a substantial contributor to regional economic activities.\n",
       "\n",
       "8. **Cultural Heritage**: The mention of \"Merah Putih\" as the national flag further emphasizes Indonesia's strong cultural identity and emphasis on its rich symbols of unity and pride.\n",
       "\n",
       "These insights highlight key aspects of Indonesia's geography, economy, politics, culture, and other relevant information that are crucial for understanding this Southeast Asian nation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class GraphRAG:\n",
    "    def __init__(self, documents, model, prompt_template):\n",
    "        self.documents = documents\n",
    "        self.model = model\n",
    "        self.prompt_template = prompt_template\n",
    "        self.graph = nx.Graph()\n",
    "        \n",
    "    def create_document_embeddings(self):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        doc_texts = [\n",
    "            \"\\n\".join(map(str, doc[0])) if isinstance(doc[0], list) else str(doc[0])\n",
    "            for doc in self.documents\n",
    "        ]\n",
    "        embeddings = vectorizer.fit_transform(doc_texts)\n",
    "        return embeddings\n",
    "    \n",
    "    def build_document_graph(self, embeddings, similarity_threshold=0.2):\n",
    "        similarity_matrix = cosine_similarity(embeddings)\n",
    "        \n",
    "        for i in range(len(self.documents)):\n",
    "            self.graph.add_node(i, text=self.documents[i])\n",
    "            \n",
    "        for i in range(len(self.documents)):\n",
    "            for j in range(i+1, len(self.documents)):\n",
    "                if similarity_matrix[i, j] > similarity_threshold:\n",
    "                    self.graph.add_edge(i, j, weight=similarity_matrix[i, j])\n",
    "    \n",
    "    def summarize_documents(self):\n",
    "        summaries = []\n",
    "        \n",
    "        chain = self.prompt_template | self.model\n",
    "        \n",
    "        for doc_index, doc_data in enumerate(self.documents):\n",
    "            if not doc_data or len(doc_data) < 4:\n",
    "                continue\n",
    "            \n",
    "            content, _, _, _ = doc_data\n",
    "            full_text = \"\\n\".join(\n",
    "                \" \".join(map(str, page)) if isinstance(page, list) else str(page)\n",
    "                for page in content\n",
    "            ) if isinstance(content, list) else str(content)\n",
    "            \n",
    "            if not full_text.strip():\n",
    "                continue\n",
    "            \n",
    "            summary = chain.invoke({\"document\": full_text})\n",
    "            summaries.append(summary)\n",
    "            \n",
    "            self.graph.nodes[doc_index]['summary'] = summary\n",
    "        \n",
    "        return summaries\n",
    "    \n",
    "    def rank_documents(self):\n",
    "        pagerank = nx.pagerank(self.graph)\n",
    "        ranked_docs = sorted(\n",
    "            [(idx, score) for idx, score in pagerank.items()], \n",
    "            key=lambda x: x[1], \n",
    "            reverse=True\n",
    "        )\n",
    "        return ranked_docs\n",
    "    \n",
    "    def generate_insights(self):\n",
    "        insights = []\n",
    "        ranked_docs = self.rank_documents()\n",
    "        \n",
    "        for idx, rank_score in ranked_docs[:3]: \n",
    "            node_data = self.graph.nodes[idx]\n",
    "            summary = node_data.get('summary', '')\n",
    "            \n",
    "            insight_prompt = f\"\"\"\n",
    "            Based on the summary of highly rated documents, \n",
    "            provide important insights:\n",
    "            \n",
    "            Summary: {summary}\n",
    "            \"\"\"\n",
    "            \n",
    "            insight = self.model.invoke(insight_prompt)\n",
    "            insights.append(insight)\n",
    "        \n",
    "        return insights\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful assistant for text summarization. \n",
    "Only include information that is part of the document. \n",
    "Do not include your own opinion or analysis.\n",
    "\n",
    "Document: \n",
    "\"{document}\"\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model=OLLAMA_MODEL)\n",
    "\n",
    "documents = list(load_documents())\n",
    "\n",
    "graph_rag = GraphRAG(documents, model, prompt)\n",
    "\n",
    "embeddings = graph_rag.create_document_embeddings()\n",
    "graph_rag.build_document_graph(embeddings)\n",
    "\n",
    "summaries = graph_rag.summarize_documents()\n",
    "\n",
    "for summary in summaries:\n",
    "    display(Markdown(summary))\n",
    "\n",
    "insights = graph_rag.generate_insights()\n",
    "print(\"\\n--- Insights ---\")\n",
    "for insight in insights:\n",
    "    display(Markdown(insight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST OLLAMA MODEL WITH RAG V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Agus Syuhada\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (21.19, 42.025999999999996, 416.0100000000002, 809.3267407407408)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n",
      "c:\\Users\\Agus Syuhada\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (21.19, 628.7959999999999, 235.94999999999993, 811.9193333333334)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The provided text appears to be a JSON-formatted list of data about Indonesia. Here is a summary of the information:\n",
       "\n",
       "**General Information**\n",
       "\n",
       "* Indonesia is located in Asia Tenggara (Southeastern Asia)\n",
       "* The country has a total area of approximately 1,904,569 square kilometers\n",
       "* The population is around 273 million people\n",
       "\n",
       "**Economy**\n",
       "\n",
       "* The GDP is estimated to be around $1.3 trillion USD (perkiraan 2024)\n",
       "* The sector economy utama is agriculture, mining, industry, and tourism\n",
       "* The country has a relatively high GDP per capita of approximately $5,000 USD\n",
       "\n",
       "**Geography**\n",
       "\n",
       "* Indonesia is bordered by Malaysia, Papua New Guinea, East Timor, Australia, and the Pacific Ocean\n",
       "* The highest mountain peak is Puncak Jaya (4,884 meters above sea level)\n",
       "* The longest river is Sungai Kapuas (approximately 1.143 kilometers long)\n",
       "\n",
       "**National Symbols**\n",
       "\n",
       "* The national symbol is the Garuda Pancasila (a five-legged bird of prey)\n",
       "* The national anthem is \"Indonesia Raya\"\n",
       "* The national flag is the Merah Putih (Red-White) flag\n",
       "* The national motto is \"Bhinneka Tunggal Ika\" (Unity in Diversity)\n",
       "\n",
       "**Other Information**\n",
       "\n",
       "* The country has a total of 17,504 islands\n",
       "* The official language is Indonesian\n",
       "* The capital city is Jakarta\n",
       "\n",
       "Note that this summary only includes the most relevant and concise information from the provided JSON data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "class SimpleSummarizer:\n",
    "    def __init__(self, documents, model, prompt_template):\n",
    "        self.documents = documents\n",
    "        self.model = model\n",
    "        self.prompt_template = prompt_template\n",
    "\n",
    "    def prepare_text(self, doc_data):\n",
    "        \"\"\"Prepare document text for summarization\"\"\"\n",
    "        if not doc_data or len(doc_data) < 4:\n",
    "            return None\n",
    "        \n",
    "        content, _, _, _ = doc_data\n",
    "        full_text = \"\\n\".join(\n",
    "            \" \".join(map(str, page)) if isinstance(page, list) else str(page)\n",
    "            for page in content\n",
    "        ) if isinstance(content, list) else str(content)\n",
    "        \n",
    "        return full_text.strip() if full_text else None\n",
    "\n",
    "    def direct_summarization(self):\n",
    "        \"\"\"Summarization for few documents\"\"\"\n",
    "        summaries = []\n",
    "        \n",
    "        for doc_data in self.documents:\n",
    "            full_text = self.prepare_text(doc_data)\n",
    "            if not full_text:\n",
    "                continue\n",
    "            \n",
    "            prompt = self.prompt_template.format(document=full_text)\n",
    "            \n",
    "            try:\n",
    "                summary = self.model.invoke(prompt)\n",
    "                summaries.append(summary)\n",
    "            except Exception as e:\n",
    "                print(f\"Error summarizing document: {e}\")\n",
    "        \n",
    "        return summaries\n",
    "\n",
    "    def simple_multi_document_summarization(self):\n",
    "        \"\"\"Summarization for more documents\"\"\"\n",
    "        return self.direct_summarization()\n",
    "\n",
    "    def summarize_documents(self):\n",
    "        \"\"\"Select summarization method based on number of documents\"\"\"\n",
    "        if len(self.documents) < 5:\n",
    "            return self.direct_summarization()\n",
    "        else:\n",
    "            return self.simple_multi_document_summarization()\n",
    "\n",
    "def create_summarizer(documents, model):\n",
    "    template = \"\"\"\n",
    "    You are a helpful assistant for text summarization. \n",
    "    Only include information that is part of the document. \n",
    "    Do not include your own opinion or analysis.\n",
    "\n",
    "    Document: \n",
    "    \"{document}\"\n",
    "    Summary:\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_template = PromptTemplate.from_template(template)\n",
    "    \n",
    "    return SimpleSummarizer(documents, model, prompt_template)\n",
    "\n",
    "try:\n",
    "    documents = list(load_documents())\n",
    "    \n",
    "    model = OllamaLLM(model=OLLAMA_MODEL)\n",
    "    \n",
    "    summarizer = create_summarizer(documents, model)\n",
    "    \n",
    "    summaries = summarizer.summarize_documents()\n",
    "    \n",
    "    for summary in summaries:\n",
    "        display(Markdown(summary))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in summarization process: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST OLLAMA MODEL WITHOUT RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Template untuk prompt summarization\n",
    "template = \"\"\"\n",
    "You are a helpful assistant for text summarization. \n",
    "Only include information that is part of the document. \n",
    "Do not include your own opinion or analysis.\n",
    "\n",
    "Document: \n",
    "\"{document}\"\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model=OLLAMA_MODEL)\n",
    "chain = prompt | model\n",
    "\n",
    "def summarize_documents(documents):\n",
    "    summaries = []\n",
    "    for doc_index, doc_data in enumerate(documents):\n",
    "        if not doc_data or len(doc_data) < 4:\n",
    "            continue\n",
    "        \n",
    "        content, _, _, _ = doc_data\n",
    "        full_text = \"\\n\".join(\n",
    "            \" \".join(map(str, page)) if isinstance(page, list) else str(page)\n",
    "            for page in content\n",
    "        ) if isinstance(content, list) else str(content)\n",
    "        \n",
    "        if not full_text.strip():\n",
    "            continue\n",
    "        \n",
    "        summaries.append(chain.invoke({\"document\": full_text}))\n",
    "    \n",
    "    return summaries\n",
    "\n",
    "documents = list(load_documents())\n",
    "summaries = summarize_documents(documents)\n",
    "\n",
    "for summary in summaries:\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST OPENAI MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_client = openai.OpenAI()  # Inisialisasi klien baru\n",
    "\n",
    "MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "\n",
    "def summarize_documents(documents):\n",
    "    summaries = []\n",
    "    for doc_index, doc_data in enumerate(documents):\n",
    "        if not doc_data or len(doc_data) < 4:\n",
    "            display(Markdown(f\"**Skipping document {doc_index} due to incomplete extraction.**\"))\n",
    "            continue\n",
    "        \n",
    "        content, _, _, _ = doc_data\n",
    "        full_text = \"\\n\".join(\n",
    "            \" \".join(map(str, page)) if isinstance(page, list) else str(page)\n",
    "            for page in content\n",
    "        ) if isinstance(content, list) else str(content)\n",
    "        \n",
    "        if not full_text.strip():\n",
    "            display(Markdown(f\"**Skipping document {doc_index} due to empty content.**\"))\n",
    "            continue\n",
    "        \n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant for text summarization. Only include information that is part of the document. Do not include your own opinion or analysis.\"},\n",
    "                {\"role\": \"user\", \"content\": full_text}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        summary = response.choices[0].message.content\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    return summaries\n",
    "\n",
    "documents = load_documents()\n",
    "summaries = summarize_documents(documents)\n",
    "\n",
    "for summary in summaries:\n",
    "    display(Markdown(summary))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
