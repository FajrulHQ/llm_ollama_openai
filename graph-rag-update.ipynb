{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"chroma\"\n",
    "DATA_PATH = \"./data\"\n",
    "OLLAMA_MODEL = \"llama3.2\"\n",
    "COLLECTION_NAME = \"ollama_vector_test\"\n",
    "\n",
    "def get_embedding_function():\n",
    "    return HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOCUMENT PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Jumlah dokumen dalam DB sebelum update: 266\n",
      "‚úÖ Tidak ada dokumen baru untuk ditambahkan\n"
     ]
    }
   ],
   "source": [
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    return document_loader.load()\n",
    "\n",
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=80,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=get_embedding_function())\n",
    "    \n",
    "    existing_docs = db.get(include=['documents', 'metadatas'])\n",
    "    \n",
    "    if isinstance(existing_docs, dict) and \"documents\" in existing_docs:\n",
    "        existing_texts = {doc.strip() for doc in existing_docs[\"documents\"]}\n",
    "    else:\n",
    "        print(\"Data dari db.get() tidak sesuai format yang diharapkan.\")\n",
    "        return db\n",
    "    \n",
    "    print(f\"üìÇ Jumlah dokumen dalam DB sebelum update: {len(existing_texts)}\")\n",
    "    \n",
    "    new_chunks = []\n",
    "    added_files = set()\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        chunk_text = chunk.page_content.strip()\n",
    "        if chunk_text not in existing_texts:\n",
    "            new_chunks.append(chunk)\n",
    "            added_files.add((chunk.metadata.get('source'), chunk.metadata.get('page')))\n",
    "    \n",
    "    if new_chunks:\n",
    "        print(f\"üìå Menambahkan {len(new_chunks)} dokumen baru...\")\n",
    "        db.add_documents(new_chunks) \n",
    "        print(f\"üîç Jumlah dokumen dalam DB setelah persist: {len(db.get(include=['documents']).get('documents', []))}\")\n",
    "        print(\"üìÑ Dokumen yang baru ditambahkan:\")\n",
    "        for file, page in added_files:\n",
    "            print(f\"   - {file} (Page {page})\")\n",
    "    else:\n",
    "        print(\"‚úÖ Tidak ada dokumen baru untuk ditambahkan\")\n",
    "    \n",
    "    return db\n",
    "\n",
    "def clear_database():\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)\n",
    "        print(\"üî• Database telah dihapus.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #clear_database()\n",
    "    documents = load_documents()\n",
    "    chunks = split_documents(documents)\n",
    "    db = add_to_chroma(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK DOCUMENTS IN DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Memeriksa konten koleksi ChromaDB...\n",
      "üìÇ Dokumen diambil: 266\n",
      "üìÑ Contoh metadata:\n",
      "- {'page': 0, 'page_label': '1', 'source': 'data\\\\22778-88667-1-PB.pdf'}\n",
      "- {'page': 0, 'page_label': '1', 'source': 'data\\\\22778-88667-1-PB.pdf'}\n",
      "- {'page': 0, 'page_label': '1', 'source': 'data\\\\22778-88667-1-PB.pdf'}\n",
      "- {'page': 0, 'page_label': '1', 'source': 'data\\\\22778-88667-1-PB.pdf'}\n",
      "- {'page': 1, 'page_label': '2', 'source': 'data\\\\22778-88667-1-PB.pdf'}\n",
      "- {'page': 1, 'page_label': '2', 'source': 'data\\\\22778-88667-1-PB.pdf'}\n",
      "- {'page': 1, 'page_label': '2', 'source': 'data\\\\22778-88667-1-PB.pdf'}\n",
      "- {'page': 1, 'page_label': '2', 'source': 'data\\\\22778-88667-1-PB.pdf'}\n",
      "- {'page': 1, 'page_label': '2', 'source': 'data\\\\22778-88667-1-PB.pdf'}\n",
      "- {'page': 1, 'page_label': '2', 'source': 'data\\\\22778-88667-1-PB.pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç Memeriksa konten koleksi ChromaDB...\")\n",
    "results = db.get(include=[\"documents\", \"metadatas\"])\n",
    "print(\"üìÇ Dokumen diambil:\", len(results.get(\"documents\", [])))\n",
    "print(\"üìÑ Contoh metadata:\")\n",
    "for meta in results.get(\"metadatas\", [])[:10]: \n",
    "    print(f\"- {meta}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING MODELS WITH GRAPHRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Dokumen yang digunakan untuk ringkasan:\n",
      "- üìÑ data\\ifransiska,+716-1511-1-PB.pdf - Page 2 (Score: 0.59)\n",
      "- üìÑ data\\Kesehatan_Mental_Masyarakat_Indonesia_Pe.pdf - Page 4 (Score: 0.59)\n",
      "- üìÑ data\\Kesehatan_Mental_Masyarakat_Indonesia_Pe.pdf - Page 4 (Score: 0.59)\n",
      "- üìÑ data\\Kesehatan_Mental_Sumber_Daya_Manusia_Ind.pdf - Page 7 (Score: 0.59)\n",
      "- üìÑ data\\Kesehatan_Mental_Sumber_Daya_Manusia_Ind.pdf - Page 0 (Score: 0.58)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Faktor utama yang mempengaruhi kesehatan mental menurut teks tersebut adalah:\n",
       "\n",
       "1. Dukungan masyarakat: Masyarakat sulit menerima kondisi para penderita gangguan kesehatan mental dan menganggap mereka sebagai orang berbahaya, pasien yang tidak dapat pulih kesehatan mentalnya.\n",
       "2. Stigma negatif masyarakat: Kuatnya stigma negatif masyarakat pada penderita gangguan kesehatan mental menjadikan penderita tidak mendapatkan perawatan yang sesuai.\n",
       "3. Wilayah: Peneliti menduga terdapat hubungan antara kondisi wilayah terhadap jumlah penderita kesehatan mental, yaitu wilayah dengan kepadatan penduduk akan menghasilkan jumlah cacat mental yang lebih tinggi.\n",
       "\n",
       "Namun, teks tersebut tidak menyebutkan secara spesifik faktor utama yang mempengaruhi kesehatan mental."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def retrieve_summary(db, query, k=5):\n",
    "    results = db.similarity_search_with_score(query, k=10)\n",
    "    if not results:\n",
    "        return \"‚ùå Tidak ada dokumen yang relevan ditemukan.\"\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    for doc, score in results:\n",
    "        source = doc.metadata['source']\n",
    "        page = doc.metadata['page']\n",
    "        G.add_node(source, page=page, content=doc.page_content)\n",
    "        G.add_edge(query, source, weight=score)\n",
    "    \n",
    "    sorted_docs = sorted(results, key=lambda x: x[1], reverse=True)[:k]\n",
    "    \n",
    "    print(\"üîé Dokumen yang digunakan untuk ringkasan:\")\n",
    "    for doc, score in sorted_docs:\n",
    "        print(f\"- üìÑ {doc.metadata['source']} - Page {doc.metadata['page']} (Score: {score:.2f})\")\n",
    "    \n",
    "    return \"\\n\".join([doc.page_content for doc, _ in sorted_docs])\n",
    "\n",
    "class GraphRAG:\n",
    "    def __init__(self, chroma_db, model, prompt_template=None):\n",
    "        self.db = chroma_db\n",
    "        self.model = model\n",
    "        self.prompt_template = prompt_template\n",
    "        self.graph = nx.Graph()\n",
    "    \n",
    "    def build_document_graph(self):\n",
    "        results = self.db.get(include=[\"documents\", \"metadatas\"])\n",
    "        docs = results.get(\"documents\", [])\n",
    "        metas = results.get(\"metadatas\", [])\n",
    "        \n",
    "        for doc, meta in zip(docs, metas):\n",
    "            if doc:\n",
    "                source = meta.get(\"source\", \"unknown\")\n",
    "                page = meta.get(\"page\", \"N/A\")\n",
    "                self.graph.add_node(source, page=page, content=doc)\n",
    "    \n",
    "    def generate_response(self, query):\n",
    "        relevant_text = retrieve_summary(self.db, query, k=5)\n",
    "        \n",
    "        if \"‚ùå Tidak ada dokumen yang relevan ditemukan.\" in relevant_text:\n",
    "            return \"Maaf, saya tidak dapat menemukan informasi yang relevan dalam dokumen yang ada.\"\n",
    "        \n",
    "        response_prompt = f\"\"\"\n",
    "        You are a helpful assistant for text summarization. \n",
    "        Only include information that is part of the document. \n",
    "        Do not include your own opinion or analysis.\n",
    "\n",
    "        Teks:\n",
    "        {relevant_text}\n",
    "\n",
    "        Pertanyaan:\n",
    "        {query}\n",
    "        \"\"\"\n",
    "    \n",
    "        response = self.model.invoke(response_prompt)\n",
    "        return response\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    embedding_function = get_embedding_function()\n",
    "    chroma_db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "    model = OllamaLLM(model=OLLAMA_MODEL)\n",
    "    \n",
    "    graph_rag = GraphRAG(chroma_db, model)\n",
    "    graph_rag.build_document_graph()\n",
    "    \n",
    "    query = \"Apa faktor utama yang mempengaruhi kesehatan mental?\"\n",
    "    response = graph_rag.generate_response(query)\n",
    "    display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
