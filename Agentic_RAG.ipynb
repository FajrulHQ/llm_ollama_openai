{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62812\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (103.42, 438.678, 526.0919999999999, 621.9063333333334)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n",
      "C:\\Users\\62812\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (139.42, 638.148, 481.82, 816.2009963636362)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n",
      "C:\\Users\\62812\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (103.42, 692.028, 523.304, 829.176)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n",
      "C:\\Users\\62812\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (57.7930041300001, 67.90079999999992, 540.6417659557536, 491.53002857142855)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n",
      "C:\\Users\\62812\\AppData\\Local\\Temp\\ipykernel_24432\\2673297948.py:48: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "from utils.document_processor import DocumentProcessor\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "# Inisialisasi pemrosesan dokumen\n",
    "docs = DocumentProcessor()\n",
    "DATA_PATH = \"./data\"\n",
    "extracted_docs = []\n",
    "valid_extensions = ('.pdf', '.docx', '.txt')\n",
    "\n",
    "# **Baca dan Proses Semua Dokumen**\n",
    "all_texts = []\n",
    "metadata_list = []\n",
    "file_texts = {}\n",
    "\n",
    "# Baca dan proses dokumen\n",
    "for filename in os.listdir(DATA_PATH):\n",
    "    if not filename.lower().endswith(valid_extensions):\n",
    "        continue  # Skip file yang tidak didukung\n",
    "\n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        document = f.read()\n",
    "        result = docs.process_document(document, filename)\n",
    "        content, images, tables, plain_text = result\n",
    "\n",
    "        # **Simpan teks per file**\n",
    "        file_texts[filename] = plain_text\n",
    "        \n",
    "        # **Split teks menjadi chunk**\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "        chunks = text_splitter.split_text(plain_text)\n",
    "\n",
    "        # **Tambahkan metadata (nama file sebagai sumber)**\n",
    "        for chunk in chunks:\n",
    "            all_texts.append(chunk)\n",
    "            metadata_list.append({\"source\": filename})\n",
    "\n",
    "# content, images, tables, plain_text = extracted_docs[0]  # Ambil file pertama\n",
    "\n",
    "# Gunakan Hugging Face embeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "vectorstore = FAISS.from_texts(all_texts, embedding_model, metadatas=metadata_list)\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST OLLAMA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_MODEL = \"llama3.2\"\n",
    "COLLECTION_NAME = \"ollama_vectore_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "  You are a helpful assistant for text summarization. \n",
    "  Only include information that is part of the document. \n",
    "  Do not include your own opinion or analysis.\n",
    "\n",
    "  Document: \n",
    "  \"{document}\"\n",
    "  Summary:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model=OLLAMA_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG AGENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval QA Chain\n",
    "retrieval_chain = RetrievalQA.from_chain_type(\n",
    "    llm=model,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# # Fungsi untuk Menampilkan Jawaban dengan Sumber\n",
    "def retrieve_answer(query):\n",
    "    response = retrieval_chain.invoke({\"query\": query})\n",
    "    answer = response[\"result\"]\n",
    "    sources = {doc.metadata[\"source\"] for doc in response[\"source_documents\"]}\n",
    "    \n",
    "    source_text = \"\\n\\n**Sumber:**\\n\" + \"\\n\".join(sources)\n",
    "    return answer + source_text\n",
    "\n",
    "# # Fungsi untuk Mengekstrak Informasi Penting dari Dokumen\n",
    "# def extract_key_info(doc_name):\n",
    "#     if doc_name in file_texts:\n",
    "#         extraction_prompt = f\"Ekstrak poin utama dari dokumen berikut:\\n\\n{file_texts[doc_name]}\\n\\nPoin utama:\"\n",
    "#         key_info = model.invoke(extraction_prompt)\n",
    "#         return f\"**Poin Utama dari {doc_name}:**\\n{key_info}\"\n",
    "#     else:\n",
    "#         return f\"Dokumen '{doc_name}' tidak ditemukan dalam sistem.\"\n",
    "\n",
    "# # Fungsi untuk Merangkum dari Informasi Penting Multi-Dokumen\n",
    "# def summarize_key_info(*_): \n",
    "#     key_points = []\n",
    "    \n",
    "#     for filename, text in file_texts.items():\n",
    "#         extraction_prompt = f\"Ekstrak poin utama dari dokumen berikut:\\n\\n{text}\\n\\nPoin utama:\"\n",
    "#         key_info = model.invoke(extraction_prompt)\n",
    "#         key_points.append(f\"**Poin Utama dari {filename}:**\\n{key_info}\")\n",
    "    \n",
    "#     combined_key_info = \"\\n\\n\".join(key_points)\n",
    "#     summarization_prompt = f\"Berdasarkan poin-poin utama berikut, buat ringkasan yang singkat dan padat:\\n\\n{combined_key_info}\\n\\nRingkasan:\"\n",
    "    \n",
    "#     summary = model.invoke(summarization_prompt)\n",
    "#     return f\"**Ringkasan Gabungan dari Semua Dokumen:**\\n{summary}\"\n",
    "\n",
    "# Fungsi untuk Ringkasan per Dokumen\n",
    "def summarize_document(doc_name):\n",
    "    if doc_name in file_texts:\n",
    "        summary_prompt = f\"Ringkas dokumen berikut:\\n\\n{file_texts[doc_name]}\\n\\nRingkasan:\"\n",
    "        summary = model.invoke(summary_prompt)\n",
    "        return f\"**Ringkasan dari {doc_name}:**\\n{summary}\"\n",
    "    else:\n",
    "        return f\"Dokumen '{doc_name}' tidak ditemukan dalam sistem.\"\n",
    "    \n",
    "# Fungsi untuk Ringkasan Semua Dokumen\n",
    "def summarize_all_documents(_=None):  # Tambahkan parameter dengan default None\n",
    "    summaries = []\n",
    "    for filename, text in file_texts.items():\n",
    "        summary_prompt = f\"Ringkas dokumen berikut:\\n\\n{text}\\n\\nRingkasan:\"\n",
    "        summary = model.invoke(summary_prompt)\n",
    "        summaries.append(f\"**Ringkasan dari {filename}:**\\n{summary}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(summaries)\n",
    "\n",
    "# Definisikan Tools untuk Agent\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"retrieval_qa\",\n",
    "        func=retrieve_answer,\n",
    "        description=\"Gunakan ini untuk menjawab pertanyaan berdasarkan dokumen yang tersedia.\"\n",
    "    ),\n",
    "    # Tool(\n",
    "    #     name=\"extract_key_info\",\n",
    "    #     func=extract_key_info,\n",
    "    #     description=\"Gunakan ini untuk mengekstrak poin utama dari satu dokumen. Masukkan nama file dokumen sebagai input.\"\n",
    "    # ),\n",
    "    # Tool(\n",
    "    #     name=\"summarize_key_info\",\n",
    "    #     func=summarize_key_info,\n",
    "    #     description=\"Gunakan ini untuk meringkas semua dokumen berdasarkan informasi penting yang telah diekstraksi.\"\n",
    "    # ),\n",
    "    Tool(\n",
    "        name=\"summarize_document\",\n",
    "        func=summarize_document,\n",
    "        description=\"Gunakan ini untuk meringkas satu dokumen. Masukkan nama file dokumen sebagai input.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"summarize_all_documents\",\n",
    "        func=summarize_all_documents,\n",
    "        description=\"Gunakan ini untuk meringkas semua dokumen yang tersedia.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62812\\AppData\\Local\\Temp\\ipykernel_24432\\2480909446.py:2: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Pertanyaan: Ringkas semua dokumen tentang kesehatan mental.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Pertanyaan untuk meringkas semua dokumen tentang kesehatan mental telah diajukan.\n",
      "\n",
      "Action: summarize_all_documents(_=None)\n",
      "Action Input: None\u001b[0m\n",
      "Observation: summarize_all_documents(_=None) is not a valid tool, try one of [retrieval_qa, summarize_document, summarize_all_documents].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: Ringkas semua dokumen tentang kesehatan mental.\n",
      "Thought: Saya harus mencari informasi yang lebih akurat tentang pengertian dan penanganan kesehatan mental.\n",
      "\n",
      "Action: summarize_document(doc_name=\"kesehatan_mental\")\n",
      "Action Input: \"kesehatan_mental\"\u001b[0m\n",
      "Observation: summarize_document(doc_name=\"kesehatan_mental\") is not a valid tool, try one of [retrieval_qa, summarize_document, summarize_all_documents].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: Ringkas semua dokumen tentang kesehatan mental.\n",
      "Thought: Saya ingin mengetahui pengertian dan penanganan kesehatan mental secara umum.\n",
      "\n",
      "Action: retrieval_qa(query=\"kesehatan mental\")\n",
      "Action Input: \"kesehatan mental\"\u001b[0m\n",
      "Observation: retrieval_qa(query=\"kesehatan mental\") is not a valid tool, try one of [retrieval_qa, summarize_document, summarize_all_documents].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: Ringkas semua dokumen tentang kesehatan mental.\n",
      "Thought: Saya ingin mengetahui pengertian dan penanganan kesehatan mental secara umum.\n",
      "\n",
      "Action: summary_all_documents(_=None)\n",
      "Action Input: None\u001b[0m\n",
      "Observation: summary_all_documents(_=None) is not a valid tool, try one of [retrieval_qa, summarize_document, summarize_all_documents].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: Ringkas semua dokumen tentang kesehatan mental.\n",
      "Thought: Saya ingin mengetahui pengertian dan penanganan kesehatan mental secara umum.\n",
      "\n",
      "Action: summary_all_documents(_=None)\n",
      "Action Input: None\u001b[0m\n",
      "Observation: summary_all_documents(_=None) is not a valid tool, try one of [retrieval_qa, summarize_document, summarize_all_documents].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: Ringkas semua dokumen tentang kesehatan mental.\n",
      "Thought: Saya ingin mengetahui pengertian dan penanganan kesehatan mental secara umum.\n",
      "\n",
      "Action: summary_all_documents(_=None)\n",
      "Action Input: None\u001b[0m\n",
      "Observation: summary_all_documents(_=None) is not a valid tool, try one of [retrieval_qa, summarize_document, summarize_all_documents].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: Ringkas semua dokumen tentang kesehatan mental.\n",
      "Thought: Saya ingin mengetahui pengertian dan penanganan kesehatan mental secara umum.\n",
      "\n",
      "Action: summary_all_documents(_=None)\n",
      "Action Input: None\u001b[0m\n",
      "Observation: summary_all_documents(_=None) is not a valid tool, try one of [retrieval_qa, summarize_document, summarize_all_documents].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: Ringkas semua dokumen tentang kesehatan mental.\n",
      "Thought: Saya ingin mengetahui pengertian dan penanganan kesehatan mental secara umum.\n",
      "\n",
      "Action: summary_all_documents(_=None)\n",
      "Action Input: None\u001b[0m\n",
      "Observation: summary_all_documents(_=None) is not a valid tool, try one of [retrieval_qa, summarize_document, summarize_all_documents].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: Ringkas semua dokumen tentang kesehatan mental.\n",
      "Thought: Saya ingin mengetahui pengertian dan penanganan kesehatan mental secara umum.\n",
      "Action: summary_document(doc_name=\"kesehatan_mental\")\n",
      "Action Input: \"kesehatan_mental\"\u001b[0m\n",
      "Observation: summary_document(doc_name=\"kesehatan_mental\") is not a valid tool, try one of [retrieval_qa, summarize_document, summarize_all_documents].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: Ringkas semua dokumen tentang kesehatan mental.\n",
      "Thought: Saya ingin mengetahui pengertian dan penanganan kesehatan mental secara umum.\n",
      "Action: summary_document(doc_name=\"kesehatan_mental\")\n",
      "Action Input: \"kesehatan_mental\"\u001b[0m\n",
      "Observation: summary_document(doc_name=\"kesehatan_mental\") is not a valid tool, try one of [retrieval_qa, summarize_document, summarize_all_documents].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: Ringkas semua dokumen tentang kesehatan mental.\n",
      "Thought: Saya ingin mengetahui pengertian dan penanganan kesehatan mental secara umum.\n",
      "\n",
      "Action: summary_document(doc_name=\"kesehatan_mental\")\n",
      "Action Input: \"kesehatan_mental\"\u001b[0m\n",
      "Observation: summary_document(doc_name=\"kesehatan_mental\") is not a valid tool, try one of [retrieval_qa, summarize_document, summarize_all_documents].\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: Ringkas semua dokumen tentang kesehatan mental secara umum adalah: Kesehatan mental adalah kondisi dimana seseorang mengalami gangguan pada pikiran atau perilakunya yang mempengaruhi keseimbangannya. Dokumentasi terkait ini mencakup penjelasan tentang jenis-jenis gangguan kesehatan mental, gejala, diagnosa, dan pengobatan yang efektif.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Final Answer:\n",
       "\n",
       "Ringkas semua dokumen tentang kesehatan mental secara umum adalah: Kesehatan mental adalah kondisi dimana seseorang mengalami gangguan pada pikiran atau perilakunya yang mempengaruhi keseimbangannya. Dokumentasi terkait ini mencakup penjelasan tentang jenis-jenis gangguan kesehatan mental, gejala, diagnosa, dan pengobatan yang efektif."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inisialisasi Agent dengan Multi-Query Handling\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=model,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# Coba Jalankan Agent dengan Pertanyaan\n",
    "queries = [\n",
    "    \"Ringkas semua dokumen tentang kesehatan mental.\"\n",
    "]\n",
    "\n",
    "# Jalankan dan Tampilkan Hasil\n",
    "for query in queries:\n",
    "    print(f\"\\n### Pertanyaan: {query}\\n\")\n",
    "    response = agent.invoke({\"input\": query})\n",
    "    \n",
    "    # Ambil final answer dari response\n",
    "    final_answer = response.get(\"output\", \"Tidak ada jawaban yang dihasilkan.\")\n",
    "    \n",
    "    # Tampilkan final answer dalam format Markdown\n",
    "    display(Markdown(f\"### Final Answer:\\n\\n{final_answer}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST OPENAI MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 8192 tokens. However, your messages resulted in 18397 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-35-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;43m        You are a helpful assistant for text summarization.\u001b[39;49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;43m        Only include information that is part of the document. \u001b[39;49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;43m        Do not include your own opinion or analysis.\u001b[39;49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;43m      \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mplain_text\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m  \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m Markdown(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: This model's maximum context length is 8192 tokens. However, your messages resulted in 18397 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model = \"gpt-35-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "  engine=model,\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\", \n",
    "      \"content\": \"\"\"\n",
    "        You are a helpful assistant for text summarization.\n",
    "        Only include information that is part of the document. \n",
    "        Do not include your own opinion or analysis.\n",
    "      \"\"\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": plain_text\n",
    "    }\n",
    "  ],\n",
    ")\n",
    "\n",
    "Markdown(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
