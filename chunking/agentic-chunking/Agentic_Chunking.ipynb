{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dokumen (1).pdf - Panjang teks sebelum pemrosesan: 3986\n",
      "Total chunks generated for Dokumen (1).pdf: 1\n",
      "Proses chunking selesai. Hasilnya disimpan dalam folder 'chunked_data' dan metadata di 'metadata'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from IPython.display import Markdown\n",
    "from phi.agent import Agent\n",
    "from phi.model.ollama import Ollama\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from utils.document_processor import DocumentProcessor  \n",
    "\n",
    "# Inisialisasi path dan model\n",
    "DATA_PATH = \"./data\"\n",
    "INDEX_PATH = \"faiss_index\"\n",
    "CHUNKED_DATA_PATH = \"./chunked_data\"  \n",
    "METADATA_PATH = \"./metadata\"  \n",
    "OLLAMA_MODEL = \"llama3.2\"\n",
    "\n",
    "# Pastikan folder tersedia\n",
    "os.makedirs(CHUNKED_DATA_PATH, exist_ok=True)\n",
    "os.makedirs(METADATA_PATH, exist_ok=True)\n",
    "\n",
    "# Inisialisasi model Ollama\n",
    "llm = Ollama(id=OLLAMA_MODEL)\n",
    "\n",
    "# Inisialisasi embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Inisialisasi document processor\n",
    "docs = DocumentProcessor()\n",
    "\n",
    "# Inisialisasi Agent dengan model Ollama\n",
    "agent = Agent(model=llm, show_tool_calls=True, markdown=True)\n",
    "\n",
    "# Langkah 1: Proses dokumen dengan agentic chunking\n",
    "extracted_docs = []\n",
    "for filename in os.listdir(DATA_PATH):\n",
    "    valid_extensions = ('.pdf', '.docx', '.txt')\n",
    "    if not filename.lower().endswith(valid_extensions):\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "\n",
    "    try:\n",
    "        # Gunakan DocumentProcessor untuk membaca file\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            document = f.read()\n",
    "            result = docs.process_document(document, filename)\n",
    "\n",
    "        if result is None:\n",
    "            print(f\"Gagal memproses {filename}, melewati file ini.\")\n",
    "            continue\n",
    "\n",
    "        plain_text = result[3]  # Pastikan indeks benar\n",
    "\n",
    "        print(f\"[INFO] {filename} - Panjang teks sebelum pemrosesan: {len(plain_text)}\")\n",
    "\n",
    "        # **Gunakan agent untuk melakukan chunking berdasarkan pemahaman konteks**\n",
    "        response = agent.run(\n",
    "            f\"Split the following document into meaningful and well-structured segments based on its content. \"\n",
    "            f\"Ensure each segment is logically coherent and can be understood independently:\\n\\n{plain_text}\",\n",
    "            max_tokens=8000\n",
    "        )\n",
    "\n",
    "        # Ambil hasil chunking dari agent\n",
    "        if isinstance(response, str):\n",
    "            structured_text = response\n",
    "        elif isinstance(response, dict):\n",
    "            structured_text = response.get(\"text\", \"\")\n",
    "        else:\n",
    "            structured_text = response.content if hasattr(response, \"content\") else str(response)\n",
    "\n",
    "        structured_text = structured_text.strip()\n",
    "\n",
    "        # Pisahkan chunk berdasarkan pemisah yang diberikan oleh agent (misalnya, menggunakan \"\\n\\n###\" sebagai pemisah)\n",
    "        chunked_texts = structured_text.split(\"\\n\\n###\")  \n",
    "\n",
    "        # Simpan hasil chunking dalam list\n",
    "        chunk_data = [{\"chunk_id\": i+1, \"text\": chunk.strip()} for i, chunk in enumerate(chunked_texts) if chunk.strip()]\n",
    "        metadata = {\"filename\": filename, \"total_chunks\": len(chunk_data)}\n",
    "\n",
    "        extracted_docs.extend([Document(page_content=chunk[\"text\"], metadata={\"chunk_id\": chunk[\"chunk_id\"], **metadata}) for chunk in chunk_data])\n",
    "\n",
    "        # Simpan hasil chunking dalam file txt\n",
    "        chunked_filepath = os.path.join(CHUNKED_DATA_PATH, f\"chunked_{filename}.txt\")\n",
    "        with open(chunked_filepath, \"w\", encoding=\"utf-8\") as chunked_file:\n",
    "            for chunk in chunk_data:\n",
    "                chunked_file.write(f\"Chunk {chunk['chunk_id']}:\\n\")\n",
    "                chunked_file.write(f\"{chunk['text']}\\n\")\n",
    "                chunked_file.write(\"\\n---\\n\\n\")  \n",
    "\n",
    "        # Simpan metadata dalam file JSON\n",
    "        metadata_filepath = os.path.join(METADATA_PATH, f\"metadata_{filename}.json\")\n",
    "        with open(metadata_filepath, \"w\", encoding=\"utf-8\") as metadata_file:\n",
    "            json.dump(metadata, metadata_file, indent=4)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "# Simpan ke FAISS secara lokal\n",
    "vector_store = FAISS.from_documents(extracted_docs, embedding_model)\n",
    "vector_store.save_local(INDEX_PATH)\n",
    "\n",
    "print(f\"Total chunks generated for {filename}: {len(chunk_data)}\")\n",
    "print(\"Proses chunking selesai. Hasilnya disimpan dalam folder 'chunked_data' dan metadata di 'metadata'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query dengan RAG\n",
    "query = \"Apa isi dokumen tentang topik X?\"\n",
    "query_embedding = embedding_model.embed_query(query)\n",
    "retrieved_docs = vector_store.similarity_search_by_vector(query_embedding, k=3)\n",
    "\n",
    "# Gabungkan dokumen hasil pencarian untuk input ke model\n",
    "retrieved_text = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST OLLAMA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_MODEL = \"llama3.2\"\n",
    "COLLECTION_NAME = \"ollama_vectore_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Berikut ringkasan dari dokumen tersebut:\n",
       "\n",
       "- PT Pertamina (Persero) atau \"PERTAMINA\" didirikan sekitar tahun 1950-an melalui pendirian PT Eksploitasi Tambang Minyak Sumatera Utara.\n",
       "- Pada 10 Desember 1957, nama perusahaan diubah menjadi PT Perusahaan Minyak Nasional (PERMINA).\n",
       "- Pada 1 Juli 1961, PERMINA ditetapkan menjadi Perusahaan Negara dengan nama PN Pertambangan Minyak Nasional (Permina).\n",
       "- Pada 20 Agustus 1968, PN Permina bergabung dengan PN Pertamin untuk membentuk PN Pertambangan Minyak dan Gas Bumi Negara (Pertamina).\n",
       "- Pada tanggal 15 Desember 1971, nama PN Pertamina diubah menjadi Perusahaan Pertambangan Minyak dan Gas Bumi Negara.\n",
       "- Pada tahun 2003, perusahaan ini berubah nama menjadi PT Pertamina (Persero) dan kemudian pada tahun 2017 menuntaskan akuisisi 72,65% saham perusahaan migas Prancis Maurel et Prom (M&P).\n",
       "- Melalui kepemilikan saham mayoritas di M&P, PERTAMINA memiliki akses operasi di 12 negara yang tersebar di 4 benua.\n",
       "- Pada tahun 2018, PT Pertamina Gas (Pertagas) bergabung dengan PT Perusahaan Gas Negara (PGN), memantapkan posisi PERTAMINA sebagai garda terdepan menjaga ketahanan energi nasional.\n",
       "- Pada 2020-2021, PERTAMINA meluncurkan Roadmap pembentukan Holding Migas dengan pembentukan Subholding Gas, Upstream Subholding, Refinery and Petrochemical Subholding, Power & NRE Subholding, Commercial and Trading Subholding, dan Integrated Marine Logistics Subholding."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "  Anda adalah asisten yang membantu dalam meringkas teks.  \n",
    "  Hanya sertakan informasi yang ada dalam dokumen.  \n",
    "  Jangan tambahkan opini atau analisis Anda sendiri.  \n",
    "\n",
    "  Dokumen:  \n",
    "  \"{document}\"  \n",
    "  Ringkasan:  \n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = OllamaLLM(model=OLLAMA_MODEL)\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke({\"document\": plain_text})\n",
    "Markdown(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST OPENAI MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "PT Pertamina (Persero) is an energy company in Indonesia that was founded in the 1950s. Initially, it was named PT Eksploitasi Tambang Minyak Sumatera Utara and was assigned by the Indonesian government to manage oil fields in Sumatra. It changed its name to PT Perusahaan Minyak Nasional (PERMINA) in 1957 and became a state-owned enterprise (PN) on 1 July 1961, with the name PN Pertambangan Minyak Nasional (Permina). PN Permina later merged with PN Pertamin and became PN Pertambangan Minyak dan Gas Bumi Negara (Pertamina) in 1968. In 2003, Pertamina changed its name to PT Pertamina (Persero). Recently, Pertamina acquired a 72.65% stake in Maurel et Prom (M&P) in 2017 and completed the acquisition of a 51% stake in Pertamina Gas (Pertagas) in 2018, which further solidified its position as a leading energy company in Indonesia. In 2020, Pertamina formed six sub-holdings to focus on specific areas of its business, including upstream, gas, refinery and petrochemical, power and NRE, commercial and trading, and integrated marine logistics. The company's vision is to become a world-class national energy company."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model = \"gpt-35-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "  engine=model,\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\", \n",
    "      \"content\": \"\"\"\n",
    "        You are a helpful assistant for text summarization.\n",
    "        Only include information that is part of the document. \n",
    "        Do not include your own opinion or analysis.\n",
    "      \"\"\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": plain_text\n",
    "    }\n",
    "  ],\n",
    ")\n",
    "\n",
    "Markdown(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
